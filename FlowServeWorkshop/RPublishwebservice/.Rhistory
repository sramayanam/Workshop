predictvalues <- function(INID1, INID2) {
    DemoData <- read.csv(file = "C:/Users/srram/Desktop/DemoData.csv", header = TRUE, row.names = NULL, encoding = "UTF-8", sep = ",", dec = ".", quote = "", comment.char = "")
    library(forecast)
    library(dplyr)
    library(plyr)
    library(ggplot2)
    min.length <- 104
    value.threshold <- 20
    test.length <- 8
    horizon <- test.length
    seasonality <- 52
    observation.freq <- "week"
    timeformat <- "%m/%d/%Y"
    INPUTID1 <- INID1
    INPUTID2 <- INID2
    data <- filter(DemoData, ID1 == INPUTID1 & ID2 == INPUTID2)
    # apply business rules
    businessrule <- function(data) {
        tsvalues <- data$obsval
        # Select Eligible Time Series:
        # Rule 1: if a time series has no more than <min.length> non-NA values, discard
        if (sum(!is.na(tsvalues)) < min.length) return(c(judge = 1))
        # Rule 2: if a time series has any sales quantity <= value.threshold , discard
        if (length(tsvalues[tsvalues > value.threshold]) != length(tsvalues)) return(c(judge = 2))
        return(c(judge = 0))
    }
    judge.all <- ddply(data, .(ID1, ID2), businessrule)
    judge.good <- judge.all[judge.all$judge == 0, c("ID1", "ID2")]
    data.good <- join(data, judge.good, by = c("ID1", "ID2"), type = "inner")
    data <- data.good
    data$time <- as.Date(data$obsdttm, format = "%m/%d/%Y")
    min.time <- min(data$time)
    max.time <- max(data$time)
    unique.time <- seq(from = min.time, to = max.time, by = "week")
    # For every (ID1, ID2) pair, create (ID1, ID2, time) combination 
    unique.ID12 <- unique(data[, 1:2])
    comb.ID1 <- rep(unique.ID12$ID1, each = length(unique.time))
    comb.ID2 <- rep(unique.ID12$ID2, each = length(unique.time))
    comb.time <- rep(unique.time, times = dim(unique.ID12)[1])
    comb <- data.frame(ID1 = comb.ID1, ID2 = comb.ID2, time = comb.time)
    # Join the combination with original data
    data <- join(comb, data, by = c("ID1", "ID2", "time"), type = "left")
    # apply business rules
    businessrule <- function(data) {
        # Train and test split
        data.length <- dim(data)[1]
        #test.length <- 52
        train.length <- data.length - test.length
        tsvalues <- data$obsval
        # Select Eligible Time Series based on training and testing principals:
        # Rule 3: if the last 6 values in trainning set are all NA, discard
        if (sum(is.na(tsvalues[(train.length - 5):train.length])) == 6) return(c(judge = 3))
        # Rule 4: if test data has more than a half NA, discard
        if (test.length > 0 && sum(is.na(tsvalues[(train.length + 1):data.length])) > test.length / 2) return(c(judge = 4))
        return(c(judge = 0))
    }
    judge.all <- ddply(data, .(ID1, ID2), businessrule)
    judge.good <- judge.all[judge.all$judge == 0, c("ID1", "ID2")]
    data.good <- join(data, judge.good, by = c("ID1", "ID2"), type = "inner")
    data <- data.good
    # Date format clean-up
    data$time <- as.POSIXct(as.numeric(as.POSIXct(data$time, format = timeformat, tz = "UTC", origin = "1970-01-01"), tz = "UTC"), tz = "UTC", origin = "1970-01-01")
    # Helper functions extracting date-related information
    weeknum <- function(date) { date <- as.Date(date, format = timeformat); as.numeric(format(date, "%U")) }
    year <- function(date) { date <- as.Date(date, format = timeformat); as.numeric(format(date, "%Y")) }
    date.info <- function(df) { date <- df$time[1]; c(year(date), weeknum(date)) }
    # Forecasting Function
    arima.single.id <- function(data) {
        method.name <- "STL_ARIMA"
        # Train and test split
        data.length <- nrow(data)
        train.length <- data.length - horizon
        train <- data[1:train.length,]
        test <- data[(train.length + 1):data.length,]
        # Missing data: replace na with average
        train$obsval[is.na(train$obsval)] <- mean(train$obsval, na.rm = TRUE)
        # Build forecasting models
        train.ts <- ts(train$obsval, frequency = seasonality, start = date.info(train))
        train.model <- stlf(train.ts, h = horizon, method = "arima", s.window = "periodic")
        forecast.value <- train.model$mean
        forecast.lo95 <- train.model$lower[, 1]
        forecast.hi95 <- train.model$upper[, 1]
        output <- data.frame(time = test$time, cbind(forecast.value, forecast.lo95, forecast.hi95))
        colnames(output)[-1] <- paste(c("forecast", "lo95", "hi95"), method.name, sep = ".")
        return(output)
    }
    ##Final forecast values in clean format
    output <- ddply(data, .(ID1, ID2), arima.single.id)
    return(output)
}
api <- publishService(      "MyService",      code = predictvalues,      inputs = list(INID1 = "numeric", INID2 = "numeric"),      outputs = list(answer = "data.frame"),      v = "v1.0.0" )
api <- publishService(      "MyService",      code = "./script.R",      inputs = list(INID1 = "numeric", INID2 = "numeric"),      outputs = list(answer = "data.frame"),      v = "v1.0.0" )
api <- publishService(      "MyService",      code = "./script.R",      inputs = list(INID1 = "numeric", INID2 = "numeric"),      outputs = list(answer = "data.frame"),      v = "v1.0.0" )api <- publishService(      "MyService", code = "C:\users\srram\documents\visual studio 2015\Projects\FridaysDemoForecast\FridaysDemoForecast\script.R",      inputs = list(INID1 = "numeric", INID2 = "numeric"),      outputs = list(answer = "data.frame"),      v = "v1.0.0" )
api <- publishService(   name =   "MyService", code = "C:\users\srram\documents\visual studio 2015\Projects\FridaysDemoForecast\FridaysDemoForecast\script.R",      inputs = list(INID1 = "numeric", INID2 = "numeric"),      outputs = list(answer = "data.frame"),      v = "v1.0.0" )
api <- publishService(   name =   "MyService", code = "C:\\users\\srram\\documents\\visual studio 2015\\Projects\\FridaysDemoForecast\\FridaysDemoForecast\\script.R",      inputs = list(INID1 = "numeric", INID2 = "numeric"),      outputs = list(answer = "data.frame"),      v = "v1.0.0" )
     outputs = list(answer = "data.frame"),
api <- publishService(   name =   "MyService", code = "C:\\Users\\srram\\documents\\visual studio 2015\\Projects\\FridaysDemoForecast\\FridaysDemoForecast\\script.R",      inputs = list(INID1 = "numeric", INID2 = "numeric"),      outputs = list(answer = "data.frame"),      v = "v1.0.0" )
api <- publishService(   name =   "MyService", code = "script.R",      inputs = list(INID1 = "numeric", INID2 = "numeric"),      outputs = list(answer = "data.frame"),      v = "v1.0.0" )
remote
remoteLogout()
pause()
remoteLogin("http://srramr1.southcentralus.cloudapp.azure.com:12800", prompt = "R>")
remoteLogin("http://srramr2.southcentralus.cloudapp.azure.com:12800", prompt = "R>")
pause()
api <- publishService(   name =   "MyService", code = "script.R",      inputs = list(INID1 = "numeric", INID2 = "numeric"),      outputs = list(answer = "data.frame"),      v = "v1.0.0" )
resume()
list
listServices()
api$ca
api$capabilities
pause()
api$c
api$capabilities
print(api)
api$capabilities
remoteLogin("http://srramr2.southcentralus.cloudapp.azure.com:12800", prompt = "R>")
pause()
api$swagger
api <- publishService(   name = "MyService", code = "script.R",      inputs = list(INID1 = "numeric", INID2 = "numeric"),      outputs = list(answer = "data.frame"),      v = "v1.0.0" )
resume()
api$swagger
api <- getService("MyService3")
library("mrsdeploy")
api <- getService("MyService")
pause()
api <- getService("MyService")
api$swagger
swagger <- api$swagger(json = FALSE)
cat(swagger)
print(swagger)
api$consume(1,2)
api$consume(2,1)
result <- api$consume(1,2)
predictvalues(1,2)
predictvalues <- function(INID1, INID2) {
    DemoData <- read.csv(file = "C:/Users/srram/Desktop/DemoData.csv", header = TRUE, row.names = NULL, encoding = "UTF-8", sep = ",", dec = ".", quote = "", comment.char = "")
    library(forecast)
    library(dplyr)
    library(plyr)
    library(ggplot2)
    min.length <- 104
    value.threshold <- 20
    test.length <- 8
    horizon <- test.length
    seasonality <- 52
    observation.freq <- "week"
    timeformat <- "%m/%d/%Y"
    INPUTID1 <- INID1
    INPUTID2 <- INID2
    data <- filter(DemoData, ID1 == INPUTID1 & ID2 == INPUTID2)
    # apply business rules
    businessrule <- function(data) {
        tsvalues <- data$obsval
        # Select Eligible Time Series:
        # Rule 1: if a time series has no more than <min.length> non-NA values, discard
        if (sum(!is.na(tsvalues)) < min.length) return(c(judge = 1))
        # Rule 2: if a time series has any sales quantity <= value.threshold , discard
        if (length(tsvalues[tsvalues > value.threshold]) != length(tsvalues)) return(c(judge = 2))
        return(c(judge = 0))
    }
    judge.all <- ddply(data, .(ID1, ID2), businessrule)
    judge.good <- judge.all[judge.all$judge == 0, c("ID1", "ID2")]
    data.good <- join(data, judge.good, by = c("ID1", "ID2"), type = "inner")
    data <- data.good
    data$time <- as.Date(data$obsdttm, format = "%m/%d/%Y")
    min.time <- min(data$time)
    max.time <- max(data$time)
    unique.time <- seq(from = min.time, to = max.time, by = "week")
    # For every (ID1, ID2) pair, create (ID1, ID2, time) combination 
    unique.ID12 <- unique(data[, 1:2])
    comb.ID1 <- rep(unique.ID12$ID1, each = length(unique.time))
    comb.ID2 <- rep(unique.ID12$ID2, each = length(unique.time))
    comb.time <- rep(unique.time, times = dim(unique.ID12)[1])
    comb <- data.frame(ID1 = comb.ID1, ID2 = comb.ID2, time = comb.time)
    # Join the combination with original data
    data <- join(comb, data, by = c("ID1", "ID2", "time"), type = "left")
    # apply business rules
    businessrule <- function(data) {
        # Train and test split
        data.length <- dim(data)[1]
        #test.length <- 52
        train.length <- data.length - test.length
        tsvalues <- data$obsval
        # Select Eligible Time Series based on training and testing principals:
        # Rule 3: if the last 6 values in trainning set are all NA, discard
        if (sum(is.na(tsvalues[(train.length - 5):train.length])) == 6) return(c(judge = 3))
        # Rule 4: if test data has more than a half NA, discard
        if (test.length > 0 && sum(is.na(tsvalues[(train.length + 1):data.length])) > test.length / 2) return(c(judge = 4))
        return(c(judge = 0))
    }
    judge.all <- ddply(data, .(ID1, ID2), businessrule)
    judge.good <- judge.all[judge.all$judge == 0, c("ID1", "ID2")]
    data.good <- join(data, judge.good, by = c("ID1", "ID2"), type = "inner")
    data <- data.good
    # Date format clean-up
    data$time <- as.POSIXct(as.numeric(as.POSIXct(data$time, format = timeformat, tz = "UTC", origin = "1970-01-01"), tz = "UTC"), tz = "UTC", origin = "1970-01-01")
    # Helper functions extracting date-related information
    weeknum <- function(date) { date <- as.Date(date, format = timeformat); as.numeric(format(date, "%U")) }
    year <- function(date) { date <- as.Date(date, format = timeformat); as.numeric(format(date, "%Y")) }
    date.info <- function(df) { date <- df$time[1]; c(year(date), weeknum(date)) }
    # Forecasting Function
    arima.single.id <- function(data) {
        method.name <- "STL_ARIMA"
        # Train and test split
        data.length <- nrow(data)
        train.length <- data.length - horizon
        train <- data[1:train.length,]
        test <- data[(train.length + 1):data.length,]
        # Missing data: replace na with average
        train$obsval[is.na(train$obsval)] <- mean(train$obsval, na.rm = TRUE)
        # Build forecasting models
        train.ts <- ts(train$obsval, frequency = seasonality, start = date.info(train))
        train.model <- stlf(train.ts, h = horizon, method = "arima", s.window = "periodic")
        forecast.value <- train.model$mean
        forecast.lo95 <- train.model$lower[, 1]
        forecast.hi95 <- train.model$upper[, 1]
        output <- data.frame(time = test$time, cbind(forecast.value, forecast.lo95, forecast.hi95))
        colnames(output)[-1] <- paste(c("forecast", "lo95", "hi95"), method.name, sep = ".")
        return(output)
    }
    ##Final forecast values in clean format
    output <- ddply(data, .(ID1, ID2), arima.single.id)
    return(output)
}
predictvalues(1,2)
predictvalues <- function(INID1, INID2) {
    DemoData <- read.csv(file = "C:/Public/Forecast/DemoData.csv", header = TRUE, row.names = NULL, encoding = "UTF-8", sep = ",", dec = ".", quote = "", comment.char = "")
    library(forecast)
    library(dplyr)
    library(plyr)
    library(ggplot2)
    min.length <- 104
    value.threshold <- 20
    test.length <- 8
    horizon <- test.length
    seasonality <- 52
    observation.freq <- "week"
    timeformat <- "%m/%d/%Y"
    INPUTID1 <- INID1
    INPUTID2 <- INID2
    data <- filter(DemoData, ID1 == INPUTID1 & ID2 == INPUTID2)
    # apply business rules
    businessrule <- function(data) {
        tsvalues <- data$obsval
        # Select Eligible Time Series:
        # Rule 1: if a time series has no more than <min.length> non-NA values, discard
        if (sum(!is.na(tsvalues)) < min.length) return(c(judge = 1))
        # Rule 2: if a time series has any sales quantity <= value.threshold , discard
        if (length(tsvalues[tsvalues > value.threshold]) != length(tsvalues)) return(c(judge = 2))
        return(c(judge = 0))
    }
    judge.all <- ddply(data, .(ID1, ID2), businessrule)
    judge.good <- judge.all[judge.all$judge == 0, c("ID1", "ID2")]
    data.good <- join(data, judge.good, by = c("ID1", "ID2"), type = "inner")
    data <- data.good
    data$time <- as.Date(data$obsdttm, format = "%m/%d/%Y")
    min.time <- min(data$time)
    max.time <- max(data$time)
    unique.time <- seq(from = min.time, to = max.time, by = "week")
    # For every (ID1, ID2) pair, create (ID1, ID2, time) combination 
    unique.ID12 <- unique(data[, 1:2])
    comb.ID1 <- rep(unique.ID12$ID1, each = length(unique.time))
    comb.ID2 <- rep(unique.ID12$ID2, each = length(unique.time))
    comb.time <- rep(unique.time, times = dim(unique.ID12)[1])
    comb <- data.frame(ID1 = comb.ID1, ID2 = comb.ID2, time = comb.time)
    # Join the combination with original data
    data <- join(comb, data, by = c("ID1", "ID2", "time"), type = "left")
    # apply business rules
    businessrule <- function(data) {
        # Train and test split
        data.length <- dim(data)[1]
        #test.length <- 52
        train.length <- data.length - test.length
        tsvalues <- data$obsval
        # Select Eligible Time Series based on training and testing principals:
        # Rule 3: if the last 6 values in trainning set are all NA, discard
        if (sum(is.na(tsvalues[(train.length - 5):train.length])) == 6) return(c(judge = 3))
        # Rule 4: if test data has more than a half NA, discard
        if (test.length > 0 && sum(is.na(tsvalues[(train.length + 1):data.length])) > test.length / 2) return(c(judge = 4))
        return(c(judge = 0))
    }
    judge.all <- ddply(data, .(ID1, ID2), businessrule)
    judge.good <- judge.all[judge.all$judge == 0, c("ID1", "ID2")]
    data.good <- join(data, judge.good, by = c("ID1", "ID2"), type = "inner")
    data <- data.good
    # Date format clean-up
    data$time <- as.POSIXct(as.numeric(as.POSIXct(data$time, format = timeformat, tz = "UTC", origin = "1970-01-01"), tz = "UTC"), tz = "UTC", origin = "1970-01-01")
    # Helper functions extracting date-related information
    weeknum <- function(date) { date <- as.Date(date, format = timeformat); as.numeric(format(date, "%U")) }
    year <- function(date) { date <- as.Date(date, format = timeformat); as.numeric(format(date, "%Y")) }
    date.info <- function(df) { date <- df$time[1]; c(year(date), weeknum(date)) }
    # Forecasting Function
    arima.single.id <- function(data) {
        method.name <- "STL_ARIMA"
        # Train and test split
        data.length <- nrow(data)
        train.length <- data.length - horizon
        train <- data[1:train.length,]
        test <- data[(train.length + 1):data.length,]
        # Missing data: replace na with average
        train$obsval[is.na(train$obsval)] <- mean(train$obsval, na.rm = TRUE)
        # Build forecasting models
        train.ts <- ts(train$obsval, frequency = seasonality, start = date.info(train))
        train.model <- stlf(train.ts, h = horizon, method = "arima", s.window = "periodic")
        forecast.value <- train.model$mean
        forecast.lo95 <- train.model$lower[, 1]
        forecast.hi95 <- train.model$upper[, 1]
        output <- data.frame(time = test$time, cbind(forecast.value, forecast.lo95, forecast.hi95))
        colnames(output)[-1] <- paste(c("forecast", "lo95", "hi95"), method.name, sep = ".")
        return(output)
    }
    ##Final forecast values in clean format
    output <- ddply(data, .(ID1, ID2), arima.single.id)
    return(output)
}
predictvalues(1,2)
resume
resume()
put
setwd("C:/Public/Forecast/")
getwd()
putLocalFile("C:/Public/Forecast/DemoData.csv")
remoteLogout
remoteLogout()
pause()
resume()
exit
remoteLogin("http://srramr2.southcentralus.cloudapp.azure.com:12800", prompt = "R>")
library("mrsdeploy")
putLocalFile("C:/Public/Forecast/DemoData.csv")
DemoData <- read.csv(file = "C:/Public/Forecast/DemoData.csv", header = TRUE, row.names = NULL, encoding = "UTF-8", sep = ",", dec = ".", quote = "", comment.char = "")
pause()
>  DemoData <- read.csv(file = "C:/Public/Forecast/DemoData.csv", header = TRUE, row.names = NULL, encoding = "UTF-8", sep = ",", dec = ".", quote = "", comment.char = "")
putLocalFile("DemoData.csv")
putLocalObject(Demo)
putLocalObject(DemoData)
putLocalObject("DemoData")
getwd
getwd()
putLocalFile("DemoData.csv")
predictvalues <- function(INID1, INID2) {
    DemoData <- read.csv(file = "C:/Public/Forecast/DemoData.csv", header = TRUE, row.names = NULL, encoding = "UTF-8", sep = ",", dec = ".", quote = "", comment.char = "")
    library(forecast)
    library(dplyr)
    library(plyr)
    library(ggplot2)
    min.length <- 104
    value.threshold <- 20
    test.length <- 8
    horizon <- test.length
    seasonality <- 52
    observation.freq <- "week"
    timeformat <- "%m/%d/%Y"
    INPUTID1 <- INID1
    INPUTID2 <- INID2
    data <- filter(DemoData, ID1 == INPUTID1 & ID2 == INPUTID2)
    # apply business rules
    businessrule <- function(data) {
        tsvalues <- data$obsval
        # Select Eligible Time Series:
        # Rule 1: if a time series has no more than <min.length> non-NA values, discard
        if (sum(!is.na(tsvalues)) < min.length) return(c(judge = 1))
        # Rule 2: if a time series has any sales quantity <= value.threshold , discard
        if (length(tsvalues[tsvalues > value.threshold]) != length(tsvalues)) return(c(judge = 2))
        return(c(judge = 0))
    }
    judge.all <- ddply(data, .(ID1, ID2), businessrule)
    judge.good <- judge.all[judge.all$judge == 0, c("ID1", "ID2")]
    data.good <- join(data, judge.good, by = c("ID1", "ID2"), type = "inner")
    data <- data.good
    data$time <- as.Date(data$obsdttm, format = "%m/%d/%Y")
    min.time <- min(data$time)
    max.time <- max(data$time)
    unique.time <- seq(from = min.time, to = max.time, by = "week")
    # For every (ID1, ID2) pair, create (ID1, ID2, time) combination 
    unique.ID12 <- unique(data[, 1:2])
    comb.ID1 <- rep(unique.ID12$ID1, each = length(unique.time))
    comb.ID2 <- rep(unique.ID12$ID2, each = length(unique.time))
    comb.time <- rep(unique.time, times = dim(unique.ID12)[1])
    comb <- data.frame(ID1 = comb.ID1, ID2 = comb.ID2, time = comb.time)
    # Join the combination with original data
    data <- join(comb, data, by = c("ID1", "ID2", "time"), type = "left")
    # apply business rules
    businessrule <- function(data) {
        # Train and test split
        data.length <- dim(data)[1]
        #test.length <- 52
        train.length <- data.length - test.length
        tsvalues <- data$obsval
        # Select Eligible Time Series based on training and testing principals:
        # Rule 3: if the last 6 values in trainning set are all NA, discard
        if (sum(is.na(tsvalues[(train.length - 5):train.length])) == 6) return(c(judge = 3))
        # Rule 4: if test data has more than a half NA, discard
        if (test.length > 0 && sum(is.na(tsvalues[(train.length + 1):data.length])) > test.length / 2) return(c(judge = 4))
        return(c(judge = 0))
    }
    judge.all <- ddply(data, .(ID1, ID2), businessrule)
    judge.good <- judge.all[judge.all$judge == 0, c("ID1", "ID2")]
    data.good <- join(data, judge.good, by = c("ID1", "ID2"), type = "inner")
    data <- data.good
    # Date format clean-up
    data$time <- as.POSIXct(as.numeric(as.POSIXct(data$time, format = timeformat, tz = "UTC", origin = "1970-01-01"), tz = "UTC"), tz = "UTC", origin = "1970-01-01")
    # Helper functions extracting date-related information
    weeknum <- function(date) { date <- as.Date(date, format = timeformat); as.numeric(format(date, "%U")) }
    year <- function(date) { date <- as.Date(date, format = timeformat); as.numeric(format(date, "%Y")) }
    date.info <- function(df) { date <- df$time[1]; c(year(date), weeknum(date)) }
    # Forecasting Function
    arima.single.id <- function(data) {
        method.name <- "STL_ARIMA"
        # Train and test split
        data.length <- nrow(data)
        train.length <- data.length - horizon
        train <- data[1:train.length,]
        test <- data[(train.length + 1):data.length,]
        # Missing data: replace na with average
        train$obsval[is.na(train$obsval)] <- mean(train$obsval, na.rm = TRUE)
        # Build forecasting models
        train.ts <- ts(train$obsval, frequency = seasonality, start = date.info(train))
        train.model <- stlf(train.ts, h = horizon, method = "arima", s.window = "periodic")
        forecast.value <- train.model$mean
        forecast.lo95 <- train.model$lower[, 1]
        forecast.hi95 <- train.model$upper[, 1]
        output <- data.frame(time = test$time, cbind(forecast.value, forecast.lo95, forecast.hi95))
        colnames(output)[-1] <- paste(c("forecast", "lo95", "hi95"), method.name, sep = ".")
        return(output)
    }
    ##Final forecast values in clean format
    output <- ddply(data, .(ID1, ID2), arima.single.id)
    return(output)
}
api <- publishService(   name =   "MyService", code = "script.R",      inputs = list(INID1 = "numeric", INID2 = "numeric"),      outputs = list(answer = "data.frame"),      v = "v1.0.1" )
api$consume(1,2)
api <- publishService(   name =   "MyService", code = predictvalues,      inputs = list(INID1 = "numeric", INID2 = "numeric"),      outputs = list(answer = "data.frame"),      v = "v1.0.2" )
api$consume(1,2)
predictvalues <- function(INID1, INID2) {
    DemoData <- read.csv(file = "C:/Users/Public/Forecast/DemoData.csv", header = TRUE, row.names = NULL, encoding = "UTF-8", sep = ",", dec = ".", quote = "", comment.char = "")
    library(forecast)
    library(dplyr)
    library(plyr)
    library(ggplot2)
    min.length <- 104
    value.threshold <- 20
    test.length <- 8
    horizon <- test.length
    seasonality <- 52
    observation.freq <- "week"
    timeformat <- "%m/%d/%Y"
    INPUTID1 <- INID1
    INPUTID2 <- INID2
    data <- filter(DemoData, ID1 == INPUTID1 & ID2 == INPUTID2)
    # apply business rules
    businessrule <- function(data) {
        tsvalues <- data$obsval
        # Select Eligible Time Series:
        # Rule 1: if a time series has no more than <min.length> non-NA values, discard
        if (sum(!is.na(tsvalues)) < min.length) return(c(judge = 1))
        # Rule 2: if a time series has any sales quantity <= value.threshold , discard
        if (length(tsvalues[tsvalues > value.threshold]) != length(tsvalues)) return(c(judge = 2))
        return(c(judge = 0))
    }
    judge.all <- ddply(data, .(ID1, ID2), businessrule)
    judge.good <- judge.all[judge.all$judge == 0, c("ID1", "ID2")]
    data.good <- join(data, judge.good, by = c("ID1", "ID2"), type = "inner")
    data <- data.good
    data$time <- as.Date(data$obsdttm, format = "%m/%d/%Y")
    min.time <- min(data$time)
    max.time <- max(data$time)
    unique.time <- seq(from = min.time, to = max.time, by = "week")
    # For every (ID1, ID2) pair, create (ID1, ID2, time) combination 
    unique.ID12 <- unique(data[, 1:2])
    comb.ID1 <- rep(unique.ID12$ID1, each = length(unique.time))
    comb.ID2 <- rep(unique.ID12$ID2, each = length(unique.time))
    comb.time <- rep(unique.time, times = dim(unique.ID12)[1])
    comb <- data.frame(ID1 = comb.ID1, ID2 = comb.ID2, time = comb.time)
    # Join the combination with original data
    data <- join(comb, data, by = c("ID1", "ID2", "time"), type = "left")
    # apply business rules
    businessrule <- function(data) {
        # Train and test split
        data.length <- dim(data)[1]
        #test.length <- 52
        train.length <- data.length - test.length
        tsvalues <- data$obsval
        # Select Eligible Time Series based on training and testing principals:
        # Rule 3: if the last 6 values in trainning set are all NA, discard
        if (sum(is.na(tsvalues[(train.length - 5):train.length])) == 6) return(c(judge = 3))
        # Rule 4: if test data has more than a half NA, discard
        if (test.length > 0 && sum(is.na(tsvalues[(train.length + 1):data.length])) > test.length / 2) return(c(judge = 4))
        return(c(judge = 0))
    }
    judge.all <- ddply(data, .(ID1, ID2), businessrule)
    judge.good <- judge.all[judge.all$judge == 0, c("ID1", "ID2")]
    data.good <- join(data, judge.good, by = c("ID1", "ID2"), type = "inner")
    data <- data.good
    # Date format clean-up
    data$time <- as.POSIXct(as.numeric(as.POSIXct(data$time, format = timeformat, tz = "UTC", origin = "1970-01-01"), tz = "UTC"), tz = "UTC", origin = "1970-01-01")
    # Helper functions extracting date-related information
    weeknum <- function(date) { date <- as.Date(date, format = timeformat); as.numeric(format(date, "%U")) }
    year <- function(date) { date <- as.Date(date, format = timeformat); as.numeric(format(date, "%Y")) }
    date.info <- function(df) { date <- df$time[1]; c(year(date), weeknum(date)) }
    # Forecasting Function
    arima.single.id <- function(data) {
        method.name <- "STL_ARIMA"
        # Train and test split
        data.length <- nrow(data)
        train.length <- data.length - horizon
        train <- data[1:train.length,]
        test <- data[(train.length + 1):data.length,]
        # Missing data: replace na with average
        train$obsval[is.na(train$obsval)] <- mean(train$obsval, na.rm = TRUE)
        # Build forecasting models
        train.ts <- ts(train$obsval, frequency = seasonality, start = date.info(train))
        train.model <- stlf(train.ts, h = horizon, method = "arima", s.window = "periodic")
        forecast.value <- train.model$mean
        forecast.lo95 <- train.model$lower[, 1]
        forecast.hi95 <- train.model$upper[, 1]
        output <- data.frame(time = test$time, cbind(forecast.value, forecast.lo95, forecast.hi95))
        colnames(output)[-1] <- paste(c("forecast", "lo95", "hi95"), method.name, sep = ".")
        return(output)
    }
    ##Final forecast values in clean format
    output <- ddply(data, .(ID1, ID2), arima.single.id)
    return(output)
}
     v = "v1.0.3"
api <- publishService(   name =   "MyService", code = predictvalues,      inputs = list(INID1 = "numeric", INID2 = "numeric"),      outputs = list(answer = "data.frame"),      v = "v1.0.3" )
api$consume(1,2)
resume()
install
install.packages("forecast")
api$consume(1,2)
api$swagger
swagger <- api$swagger() cat(swagger, file = "swagger.json", append = FALSE)
remoteLogin("http://srramr2.southcentralus.cloudapp.azure.com:12800", prompt = "R>")
pause
pause()
api<-getService("MyService")
api$consume(1,2)
api <- publishService(   name =   "MyService", code = predictvalues,      inputs = list(INID1 = "numeric", INID2 = "numeric"),     # outputs = list(answer = "data.frame"),      v = "v1.0.4" )
predictvalues <- function(INID1, INID2) {
    DemoData <- read.csv(file = "C:/Users/Public/Forecast/DemoData.csv", header = TRUE, row.names = NULL, encoding = "UTF-8", sep = ",", dec = ".", quote = "", comment.char = "")
    library(forecast)
    library(dplyr)
    library(plyr)
    library(ggplot2)
    min.length <- 104
    value.threshold <- 20
    test.length <- 8
    horizon <- test.length
    seasonality <- 52
    observation.freq <- "week"
    timeformat <- "%m/%d/%Y"
    INPUTID1 <- INID1
    INPUTID2 <- INID2
    data <- filter(DemoData, ID1 == INPUTID1 & ID2 == INPUTID2)
    # apply business rules
    businessrule <- function(data) {
        tsvalues <- data$obsval
        # Select Eligible Time Series:
        # Rule 1: if a time series has no more than <min.length> non-NA values, discard
        if (sum(!is.na(tsvalues)) < min.length) return(c(judge = 1))
        # Rule 2: if a time series has any sales quantity <= value.threshold , discard
        if (length(tsvalues[tsvalues > value.threshold]) != length(tsvalues)) return(c(judge = 2))
        return(c(judge = 0))
    }
    judge.all <- ddply(data, .(ID1, ID2), businessrule)
    judge.good <- judge.all[judge.all$judge == 0, c("ID1", "ID2")]
    data.good <- join(data, judge.good, by = c("ID1", "ID2"), type = "inner")
    data <- data.good
    data$time <- as.Date(data$obsdttm, format = "%m/%d/%Y")
    min.time <- min(data$time)
    max.time <- max(data$time)
    unique.time <- seq(from = min.time, to = max.time, by = "week")
    # For every (ID1, ID2) pair, create (ID1, ID2, time) combination 
    unique.ID12 <- unique(data[, 1:2])
    comb.ID1 <- rep(unique.ID12$ID1, each = length(unique.time))
    comb.ID2 <- rep(unique.ID12$ID2, each = length(unique.time))
    comb.time <- rep(unique.time, times = dim(unique.ID12)[1])
    comb <- data.frame(ID1 = comb.ID1, ID2 = comb.ID2, time = comb.time)
    # Join the combination with original data
    data <- join(comb, data, by = c("ID1", "ID2", "time"), type = "left")
    # apply business rules
    businessrule <- function(data) {
        # Train and test split
        data.length <- dim(data)[1]
        #test.length <- 52
        train.length <- data.length - test.length
        tsvalues <- data$obsval
        # Select Eligible Time Series based on training and testing principals:
        # Rule 3: if the last 6 values in trainning set are all NA, discard
        if (sum(is.na(tsvalues[(train.length - 5):train.length])) == 6) return(c(judge = 3))
        # Rule 4: if test data has more than a half NA, discard
        if (test.length > 0 && sum(is.na(tsvalues[(train.length + 1):data.length])) > test.length / 2) return(c(judge = 4))
        return(c(judge = 0))
    }
    judge.all <- ddply(data, .(ID1, ID2), businessrule)
    judge.good <- judge.all[judge.all$judge == 0, c("ID1", "ID2")]
    data.good <- join(data, judge.good, by = c("ID1", "ID2"), type = "inner")
    data <- data.good
    # Date format clean-up
    data$time <- as.POSIXct(as.numeric(as.POSIXct(data$time, format = timeformat, tz = "UTC", origin = "1970-01-01"), tz = "UTC"), tz = "UTC", origin = "1970-01-01")
    # Helper functions extracting date-related information
    weeknum <- function(date) { date <- as.Date(date, format = timeformat); as.numeric(format(date, "%U")) }
    year <- function(date) { date <- as.Date(date, format = timeformat); as.numeric(format(date, "%Y")) }
    date.info <- function(df) { date <- df$time[1]; c(year(date), weeknum(date)) }
    # Forecasting Function
    arima.single.id <- function(data) {
        method.name <- "STL_ARIMA"
        # Train and test split
        data.length <- nrow(data)
        train.length <- data.length - horizon
        train <- data[1:train.length,]
        test <- data[(train.length + 1):data.length,]
        # Missing data: replace na with average
        train$obsval[is.na(train$obsval)] <- mean(train$obsval, na.rm = TRUE)
        # Build forecasting models
        train.ts <- ts(train$obsval, frequency = seasonality, start = date.info(train))
        train.model <- stlf(train.ts, h = horizon, method = "arima", s.window = "periodic")
        forecast.value <- train.model$mean
        forecast.lo95 <- train.model$lower[, 1]
        forecast.hi95 <- train.model$upper[, 1]
        output <- data.frame(time = test$time, cbind(forecast.value, forecast.lo95, forecast.hi95))
        colnames(output)[-1] <- paste(c("forecast", "lo95", "hi95"), method.name, sep = ".")
        return(output)
    }
    ##Final forecast values in clean format
    output <- ddply(data, .(ID1, ID2), arima.single.id)
    return(output)
}
api <- publishService(   name =   "MyService", code = predictvalues,      inputs = list(INID1 = "numeric", INID2 = "numeric"),     # outputs = list(answer = "data.frame"),      v = "v1.0.4" )
api <- gerService("MyService")
api <- getService("MyService")
api$consume(1,2)
cap <- api$capabilities()
print(cap$outputs)
api <- publishService(   name =   "MyService", code = predictvalues,      inputs = list(INID1 = "numeric", INID2 = "numeric"),      outputs = list(answer = "data.frame"),      v = "v1.0.5" )
api <- getService("MyService",v = "v1.0.5")
api$consume(1,2)
api$consume(1,2)
result <- api$consume(1,2)
result$output("answer")
result$output
result$output[,]
print(result$output)
api <- publishService(   name =   "forecastservice", code = predictvalues,      inputs = list(INID1 = "integer", INID2 = "integer"),      outputs = list(answer = "data.frame"),      v = "v1.0.0" )
api <- getService("forecastservice")
result <- api$predictvalues(1,2)
api <- publishService(   name =   "forecastservice", code = predictvalues,      inputs = list(INID1 = "numeric", INID2 = "numeric"),      outputs = list(answer = "data.frame"),      v = "v1.0.1" )
api <- getService("forecastservice",version = "v1.0.1")
api <- getService("forecastservice",ve = "v1.0.1")
api <- getService("forecastservice",version = "v1.0.1")
api <- getService("forecastservice",v = "v1.0.1")
result <- api$predictvalues(2,1)
api$predictvalues(2,1)
result1 <- api$predictvalues(2,1)
result1$output[1,1]
result1$output[,1]
api <- publishService(   name =   "forecastservice", code = predictvalues,      inputs = list(INID1 = "numeric", INID2 = "numeric"),      outputs = list(srramo = "data.frame"),      v = "v1.0.2" )
api <- getService("forecastservice", v = "v1.0.2")
result2 <= api$consume(1,2)
result2 <- api$consume(1,2)
api$consume(1,2)
result2 <- api$consume(1,2)
as.data.frame(result2)
as.data.frame(result2$output)
result2$output
result2$output()
result2$output(1)
result2$output()[,]
result2$output()[,1]
is.
is.data.frame(result2$output())
is.data.frame(result2$output()$srramo)
result2$output()$srramo
result2$output$srram0
result2$output()$srramo
resume()
predictvalues <- function(INID1, INID2) {
    DemoData <- read.csv(file = "C:/Users/Public/Forecast/DemoData.csv", header = TRUE, row.names = NULL, encoding = "UTF-8", sep = ",", dec = ".", quote = "", comment.char = "")
    library(forecast)
    library(dplyr)
    library(plyr)
    library(ggplot2)
    min.length <- 104
    value.threshold <- 20
    test.length <- 8
    horizon <- test.length
    seasonality <- 52
    observation.freq <- "week"
    timeformat <- "%m/%d/%Y"
    INPUTID1 <- INID1
    INPUTID2 <- INID2
    data <- filter(DemoData, ID1 == INPUTID1 & ID2 == INPUTID2)
    # apply business rules
    businessrule <- function(data) {
        tsvalues <- data$obsval
        # Select Eligible Time Series:
        # Rule 1: if a time series has no more than <min.length> non-NA values, discard
        if (sum(!is.na(tsvalues)) < min.length) return(c(judge = 1))
        # Rule 2: if a time series has any sales quantity <= value.threshold , discard
        if (length(tsvalues[tsvalues > value.threshold]) != length(tsvalues)) return(c(judge = 2))
        return(c(judge = 0))
    }
    judge.all <- ddply(data, .(ID1, ID2), businessrule)
    judge.good <- judge.all[judge.all$judge == 0, c("ID1", "ID2")]
    data.good <- join(data, judge.good, by = c("ID1", "ID2"), type = "inner")
    data <- data.good
    data$time <- as.Date(data$obsdttm, format = "%m/%d/%Y")
    min.time <- min(data$time)
    max.time <- max(data$time)
    unique.time <- seq(from = min.time, to = max.time, by = "week")
    # For every (ID1, ID2) pair, create (ID1, ID2, time) combination 
    unique.ID12 <- unique(data[, 1:2])
    comb.ID1 <- rep(unique.ID12$ID1, each = length(unique.time))
    comb.ID2 <- rep(unique.ID12$ID2, each = length(unique.time))
    comb.time <- rep(unique.time, times = dim(unique.ID12)[1])
    comb <- data.frame(ID1 = comb.ID1, ID2 = comb.ID2, time = comb.time)
    # Join the combination with original data
    data <- join(comb, data, by = c("ID1", "ID2", "time"), type = "left")
    # apply business rules
    businessrule <- function(data) {
        # Train and test split
        data.length <- dim(data)[1]
        #test.length <- 52
        train.length <- data.length - test.length
        tsvalues <- data$obsval
        # Select Eligible Time Series based on training and testing principals:
        # Rule 3: if the last 6 values in trainning set are all NA, discard
        if (sum(is.na(tsvalues[(train.length - 5):train.length])) == 6) return(c(judge = 3))
        # Rule 4: if test data has more than a half NA, discard
        if (test.length > 0 && sum(is.na(tsvalues[(train.length + 1):data.length])) > test.length / 2) return(c(judge = 4))
        return(c(judge = 0))
    }
    judge.all <- ddply(data, .(ID1, ID2), businessrule)
    judge.good <- judge.all[judge.all$judge == 0, c("ID1", "ID2")]
    data.good <- join(data, judge.good, by = c("ID1", "ID2"), type = "inner")
    data <- data.good
    # Date format clean-up
    data$time <- as.POSIXct(as.numeric(as.POSIXct(data$time, format = timeformat, tz = "UTC", origin = "1970-01-01"), tz = "UTC"), tz = "UTC", origin = "1970-01-01")
    # Helper functions extracting date-related information
    weeknum <- function(date) { date <- as.Date(date, format = timeformat); as.numeric(format(date, "%U")) }
    year <- function(date) { date <- as.Date(date, format = timeformat); as.numeric(format(date, "%Y")) }
    date.info <- function(df) { date <- df$time[1]; c(year(date), weeknum(date)) }
    # Forecasting Function
    arima.single.id <- function(data) {
        method.name <- "STL_ARIMA"
        # Train and test split
        data.length <- nrow(data)
        train.length <- data.length - horizon
        train <- data[1:train.length,]
        test <- data[(train.length + 1):data.length,]
        # Missing data: replace na with average
        train$obsval[is.na(train$obsval)] <- mean(train$obsval, na.rm = TRUE)
        # Build forecasting models
        train.ts <- ts(train$obsval, frequency = seasonality, start = date.info(train))
        train.model <- stlf(train.ts, h = horizon, method = "arima", s.window = "periodic")
        forecast.value <- train.model$mean
        forecast.lo95 <- train.model$lower[, 1]
        forecast.hi95 <- train.model$upper[, 1]
        output <- data.frame(time = test$time, cbind(forecast.value, forecast.lo95, forecast.hi95))
        colnames(output)[-1] <- paste(c("forecast", "lo95", "hi95"), method.name, sep = ".")
        return(output)
    }
    ##Final forecast values in clean format
    output <- ddply(data, .(ID1, ID2), arima.single.id)
    return(output)
}
publishService(2,1)
predictvalues(2,1)
pause()
result2$output$out
result2$output()$out
result2$output()
resume
resume()
pause()
resume()
predictvalues(2,1)
predictvalues <- function(INID1, INID2) {
    DemoData <- read.csv(file = "C:/Users/Public/Forecast/DemoData.csv", header = TRUE, row.names = NULL, encoding = "UTF-8", sep = ",", dec = ".", quote = "", comment.char = "")
    library(forecast)
    library(dplyr)
    library(plyr)
    library(ggplot2)
    min.length <- 104
    value.threshold <- 20
    test.length <- 8
    horizon <- test.length
    seasonality <- 52
    observation.freq <- "week"
    timeformat <- "%m/%d/%Y"
    INPUTID1 <- INID1
    INPUTID2 <- INID2
    data <- filter(DemoData, ID1 == INPUTID1 & ID2 == INPUTID2)
    # apply business rules
    businessrule <- function(data) {
        tsvalues <- data$obsval
        # Select Eligible Time Series:
        # Rule 1: if a time series has no more than <min.length> non-NA values, discard
        if (sum(!is.na(tsvalues)) < min.length) return(c(judge = 1))
        # Rule 2: if a time series has any sales quantity <= value.threshold , discard
        if (length(tsvalues[tsvalues > value.threshold]) != length(tsvalues)) return(c(judge = 2))
        return(c(judge = 0))
    }
    judge.all <- ddply(data, .(ID1, ID2), businessrule)
    judge.good <- judge.all[judge.all$judge == 0, c("ID1", "ID2")]
    data.good <- join(data, judge.good, by = c("ID1", "ID2"), type = "inner")
    data <- data.good
    data$time <- as.Date(data$obsdttm, format = "%m/%d/%Y")
    min.time <- min(data$time)
    max.time <- max(data$time)
    unique.time <- seq(from = min.time, to = max.time, by = "week")
    # For every (ID1, ID2) pair, create (ID1, ID2, time) combination 
    unique.ID12 <- unique(data[, 1:2])
    comb.ID1 <- rep(unique.ID12$ID1, each = length(unique.time))
    comb.ID2 <- rep(unique.ID12$ID2, each = length(unique.time))
    comb.time <- rep(unique.time, times = dim(unique.ID12)[1])
    comb <- data.frame(ID1 = comb.ID1, ID2 = comb.ID2, time = comb.time)
    # Join the combination with original data
    data <- join(comb, data, by = c("ID1", "ID2", "time"), type = "left")
    # apply business rules
    businessrule <- function(data) {
        # Train and test split
        data.length <- dim(data)[1]
        #test.length <- 52
        train.length <- data.length - test.length
        tsvalues <- data$obsval
        # Select Eligible Time Series based on training and testing principals:
        # Rule 3: if the last 6 values in trainning set are all NA, discard
        if (sum(is.na(tsvalues[(train.length - 5):train.length])) == 6) return(c(judge = 3))
        # Rule 4: if test data has more than a half NA, discard
        if (test.length > 0 && sum(is.na(tsvalues[(train.length + 1):data.length])) > test.length / 2) return(c(judge = 4))
        return(c(judge = 0))
    }
    judge.all <- ddply(data, .(ID1, ID2), businessrule)
    judge.good <- judge.all[judge.all$judge == 0, c("ID1", "ID2")]
    data.good <- join(data, judge.good, by = c("ID1", "ID2"), type = "inner")
    data <- data.good
    # Date format clean-up
    data$time <- as.POSIXct(as.numeric(as.POSIXct(data$time, format = timeformat, tz = "UTC", origin = "1970-01-01"), tz = "UTC"), tz = "UTC", origin = "1970-01-01")
    # Helper functions extracting date-related information
    weeknum <- function(date) { date <- as.Date(date, format = timeformat); as.numeric(format(date, "%U")) }
    year <- function(date) { date <- as.Date(date, format = timeformat); as.numeric(format(date, "%Y")) }
    date.info <- function(df) { date <- df$time[1]; c(year(date), weeknum(date)) }
    # Forecasting Function
    arima.single.id <- function(data) {
        method.name <- "STL_ARIMA"
        # Train and test split
        data.length <- nrow(data)
        train.length <- data.length - horizon
        train <- data[1:train.length,]
        test <- data[(train.length + 1):data.length,]
        # Missing data: replace na with average
        train$obsval[is.na(train$obsval)] <- mean(train$obsval, na.rm = TRUE)
        # Build forecasting models
        train.ts <- ts(train$obsval, frequency = seasonality, start = date.info(train))
        train.model <- stlf(train.ts, h = horizon, method = "arima", s.window = "periodic")
        forecast.value <- train.model$mean
        forecast.lo95 <- train.model$lower[, 1]
        forecast.hi95 <- train.model$upper[, 1]
        output <- data.frame(time = test$time, cbind(forecast.value, forecast.lo95, forecast.hi95))
        colnames(output)[-1] <- paste(c("forecast", "lo95", "hi95"), method.name, sep = ".")
        return(output)
    }
    ##Final forecast values in clean format
    output <- ddply(data, .(ID1, ID2), arima.single.id)
    forecastedvalue <- filter(output, as.Date(time, format = "%m/%d/%Y") == as.Date("12/28/2013", format = "%m/%d/%Y"))
    return(forecastedvalue$forecastSTL_ARIMA)
}
predictvalues(2,1)
predictvalues <- function(INID1, INID2) {
    DemoData <- read.csv(file = "C:/Users/Public/Forecast/DemoData.csv", header = TRUE, row.names = NULL, encoding = "UTF-8", sep = ",", dec = ".", quote = "", comment.char = "")
    library(forecast)
    library(dplyr)
    library(plyr)
    library(ggplot2)
    min.length <- 104
    value.threshold <- 20
    test.length <- 8
    horizon <- test.length
    seasonality <- 52
    observation.freq <- "week"
    timeformat <- "%m/%d/%Y"
    INPUTID1 <- INID1
    INPUTID2 <- INID2
    data <- filter(DemoData, ID1 == INPUTID1 & ID2 == INPUTID2)
    # apply business rules
    businessrule <- function(data) {
        tsvalues <- data$obsval
        # Select Eligible Time Series:
        # Rule 1: if a time series has no more than <min.length> non-NA values, discard
        if (sum(!is.na(tsvalues)) < min.length) return(c(judge = 1))
        # Rule 2: if a time series has any sales quantity <= value.threshold , discard
        if (length(tsvalues[tsvalues > value.threshold]) != length(tsvalues)) return(c(judge = 2))
        return(c(judge = 0))
    }
    judge.all <- ddply(data, .(ID1, ID2), businessrule)
    judge.good <- judge.all[judge.all$judge == 0, c("ID1", "ID2")]
    data.good <- join(data, judge.good, by = c("ID1", "ID2"), type = "inner")
    data <- data.good
    data$time <- as.Date(data$obsdttm, format = "%m/%d/%Y")
    min.time <- min(data$time)
    max.time <- max(data$time)
    unique.time <- seq(from = min.time, to = max.time, by = "week")
    # For every (ID1, ID2) pair, create (ID1, ID2, time) combination 
    unique.ID12 <- unique(data[, 1:2])
    comb.ID1 <- rep(unique.ID12$ID1, each = length(unique.time))
    comb.ID2 <- rep(unique.ID12$ID2, each = length(unique.time))
    comb.time <- rep(unique.time, times = dim(unique.ID12)[1])
    comb <- data.frame(ID1 = comb.ID1, ID2 = comb.ID2, time = comb.time)
    # Join the combination with original data
    data <- join(comb, data, by = c("ID1", "ID2", "time"), type = "left")
    # apply business rules
    businessrule <- function(data) {
        # Train and test split
        data.length <- dim(data)[1]
        #test.length <- 52
        train.length <- data.length - test.length
        tsvalues <- data$obsval
        # Select Eligible Time Series based on training and testing principals:
        # Rule 3: if the last 6 values in trainning set are all NA, discard
        if (sum(is.na(tsvalues[(train.length - 5):train.length])) == 6) return(c(judge = 3))
        # Rule 4: if test data has more than a half NA, discard
        if (test.length > 0 && sum(is.na(tsvalues[(train.length + 1):data.length])) > test.length / 2) return(c(judge = 4))
        return(c(judge = 0))
    }
    judge.all <- ddply(data, .(ID1, ID2), businessrule)
    judge.good <- judge.all[judge.all$judge == 0, c("ID1", "ID2")]
    data.good <- join(data, judge.good, by = c("ID1", "ID2"), type = "inner")
    data <- data.good
    # Date format clean-up
    data$time <- as.POSIXct(as.numeric(as.POSIXct(data$time, format = timeformat, tz = "UTC", origin = "1970-01-01"), tz = "UTC"), tz = "UTC", origin = "1970-01-01")
    # Helper functions extracting date-related information
    weeknum <- function(date) { date <- as.Date(date, format = timeformat); as.numeric(format(date, "%U")) }
    year <- function(date) { date <- as.Date(date, format = timeformat); as.numeric(format(date, "%Y")) }
    date.info <- function(df) { date <- df$time[1]; c(year(date), weeknum(date)) }
    # Forecasting Function
    arima.single.id <- function(data) {
        method.name <- "STL_ARIMA"
        # Train and test split
        data.length <- nrow(data)
        train.length <- data.length - horizon
        train <- data[1:train.length,]
        test <- data[(train.length + 1):data.length,]
        # Missing data: replace na with average
        train$obsval[is.na(train$obsval)] <- mean(train$obsval, na.rm = TRUE)
        # Build forecasting models
        train.ts <- ts(train$obsval, frequency = seasonality, start = date.info(train))
        train.model <- stlf(train.ts, h = horizon, method = "arima", s.window = "periodic")
        forecast.value <- train.model$mean
        forecast.lo95 <- train.model$lower[, 1]
        forecast.hi95 <- train.model$upper[, 1]
        output <- data.frame(time = test$time, cbind(forecast.value, forecast.lo95, forecast.hi95))
        colnames(output)[-1] <- paste(c("forecast", "lo95", "hi95"), method.name, sep = ".")
        return(output)
    }
    ##Final forecast values in clean format
    output <- ddply(data, .(ID1, ID2), arima.single.id)
    forecastedvalue <- filter(output, as.Date(time, format = "%m/%d/%Y") == as.Date("12/28/2013", format = "%m/%d/%Y"))
    return(forecastedvalue$forecast.STL_ARIMA)
}
predictvalues(2,1)
    DemoData <- read.csv(file = "C:/Users/Public/Forecast/DemoData.csv", header = TRUE, row.names = NULL, encoding = "UTF-8", sep = ",", dec = ".", quote = "", comment.char = "")
    library(forecast)
    library(dplyr)
    library(plyr)
    library(ggplot2)
    min.length <- 104
    value.threshold <- 20
    test.length <- 8
    horizon <- test.length
    seasonality <- 52
    observation.freq <- "week"
    timeformat <- "%m/%d/%Y"
    INPUTID1 <- INID1
    INPUTID2 <- INID2
    data <- filter(DemoData, ID1 == INPUTID1 & ID2 == INPUTID2)
    # apply business rules
    businessrule <- function(data) {
        tsvalues <- data$obsval
        # Select Eligible Time Series:
        # Rule 1: if a time series has no more than <min.length> non-NA values, discard
        if (sum(!is.na(tsvalues)) < min.length) return(c(judge = 1))
        # Rule 2: if a time series has any sales quantity <= value.threshold , discard
        if (length(tsvalues[tsvalues > value.threshold]) != length(tsvalues)) return(c(judge = 2))
        return(c(judge = 0))
    }
    judge.all <- ddply(data, .(ID1, ID2), businessrule)
    judge.good <- judge.all[judge.all$judge == 0, c("ID1", "ID2")]
    data.good <- join(data, judge.good, by = c("ID1", "ID2"), type = "inner")
    data <- data.good
    data$time <- as.Date(data$obsdttm, format = "%m/%d/%Y")
    min.time <- min(data$time)
    max.time <- max(data$time)
    unique.time <- seq(from = min.time, to = max.time, by = "week")
    # For every (ID1, ID2) pair, create (ID1, ID2, time) combination 
    unique.ID12 <- unique(data[, 1:2])
    comb.ID1 <- rep(unique.ID12$ID1, each = length(unique.time))
    comb.ID2 <- rep(unique.ID12$ID2, each = length(unique.time))
    comb.time <- rep(unique.time, times = dim(unique.ID12)[1])
    comb <- data.frame(ID1 = comb.ID1, ID2 = comb.ID2, time = comb.time)
    # Join the combination with original data
    data <- join(comb, data, by = c("ID1", "ID2", "time"), type = "left")
    # apply business rules
    businessrule <- function(data) {
        # Train and test split
        data.length <- dim(data)[1]
        #test.length <- 52
        train.length <- data.length - test.length
        tsvalues <- data$obsval
        # Select Eligible Time Series based on training and testing principals:
        # Rule 3: if the last 6 values in trainning set are all NA, discard
        if (sum(is.na(tsvalues[(train.length - 5):train.length])) == 6) return(c(judge = 3))
        # Rule 4: if test data has more than a half NA, discard
        if (test.length > 0 && sum(is.na(tsvalues[(train.length + 1):data.length])) > test.length / 2) return(c(judge = 4))
        return(c(judge = 0))
    }
    judge.all <- ddply(data, .(ID1, ID2), businessrule)
    judge.good <- judge.all[judge.all$judge == 0, c("ID1", "ID2")]
    data.good <- join(data, judge.good, by = c("ID1", "ID2"), type = "inner")
    data <- data.good
    # Date format clean-up
    data$time <- as.POSIXct(as.numeric(as.POSIXct(data$time, format = timeformat, tz = "UTC", origin = "1970-01-01"), tz = "UTC"), tz = "UTC", origin = "1970-01-01")
    # Helper functions extracting date-related information
    weeknum <- function(date) { date <- as.Date(date, format = timeformat); as.numeric(format(date, "%U")) }
    year <- function(date) { date <- as.Date(date, format = timeformat); as.numeric(format(date, "%Y")) }
    date.info <- function(df) { date <- df$time[1]; c(year(date), weeknum(date)) }
    # Forecasting Function
    arima.single.id <- function(data) {
        method.name <- "STL_ARIMA"
        # Train and test split
        data.length <- nrow(data)
        train.length <- data.length - horizon
        train <- data[1:train.length,]
        test <- data[(train.length + 1):data.length,]
        # Missing data: replace na with average
        train$obsval[is.na(train$obsval)] <- mean(train$obsval, na.rm = TRUE)
        # Build forecasting models
        train.ts <- ts(train$obsval, frequency = seasonality, start = date.info(train))
        train.model <- stlf(train.ts, h = horizon, method = "arima", s.window = "periodic")
        forecast.value <- train.model$mean
        forecast.lo95 <- train.model$lower[, 1]
        forecast.hi95 <- train.model$upper[, 1]
        output <- data.frame(time = test$time, cbind(forecast.value, forecast.lo95, forecast.hi95))
        colnames(output)[-1] <- paste(c("forecast", "lo95", "hi95"), method.name, sep = ".")
        return(output)
    }
    ##Final forecast values in clean format
    output <- ddply(data, .(ID1, ID2), arima.single.id)
    forecastedvalue <- filter(output, as.Date(time, format = "%m/%d/%Y") == as.Date("12/28/2013", format = "%m/%d/%Y"))
output
predictvalues <- function(INID1, INID2) {
    DemoData <- read.csv(file = "C:/Users/Public/Forecast/DemoData.csv", header = TRUE, row.names = NULL, encoding = "UTF-8", sep = ",", dec = ".", quote = "", comment.char = "")
    library(forecast)
    library(dplyr)
    library(plyr)
    library(ggplot2)
    min.length <- 104
    value.threshold <- 20
    test.length <- 8
    horizon <- test.length
    seasonality <- 52
    observation.freq <- "week"
    timeformat <- "%m/%d/%Y"
    INPUTID1 <- INID1
    INPUTID2 <- INID2
    data <- filter(DemoData, ID1 == INPUTID1 & ID2 == INPUTID2)
    # apply business rules
    businessrule <- function(data) {
        tsvalues <- data$obsval
        # Select Eligible Time Series:
        # Rule 1: if a time series has no more than <min.length> non-NA values, discard
        if (sum(!is.na(tsvalues)) < min.length) return(c(judge = 1))
        # Rule 2: if a time series has any sales quantity <= value.threshold , discard
        if (length(tsvalues[tsvalues > value.threshold]) != length(tsvalues)) return(c(judge = 2))
        return(c(judge = 0))
    }
    judge.all <- ddply(data, .(ID1, ID2), businessrule)
    judge.good <- judge.all[judge.all$judge == 0, c("ID1", "ID2")]
    data.good <- join(data, judge.good, by = c("ID1", "ID2"), type = "inner")
    data <- data.good
    data$time <- as.Date(data$obsdttm, format = "%m/%d/%Y")
    min.time <- min(data$time)
    max.time <- max(data$time)
    unique.time <- seq(from = min.time, to = max.time, by = "week")
    # For every (ID1, ID2) pair, create (ID1, ID2, time) combination 
    unique.ID12 <- unique(data[, 1:2])
    comb.ID1 <- rep(unique.ID12$ID1, each = length(unique.time))
    comb.ID2 <- rep(unique.ID12$ID2, each = length(unique.time))
    comb.time <- rep(unique.time, times = dim(unique.ID12)[1])
    comb <- data.frame(ID1 = comb.ID1, ID2 = comb.ID2, time = comb.time)
    # Join the combination with original data
    data <- join(comb, data, by = c("ID1", "ID2", "time"), type = "left")
    # apply business rules
    businessrule <- function(data) {
        # Train and test split
        data.length <- dim(data)[1]
        #test.length <- 52
        train.length <- data.length - test.length
        tsvalues <- data$obsval
        # Select Eligible Time Series based on training and testing principals:
        # Rule 3: if the last 6 values in trainning set are all NA, discard
        if (sum(is.na(tsvalues[(train.length - 5):train.length])) == 6) return(c(judge = 3))
        # Rule 4: if test data has more than a half NA, discard
        if (test.length > 0 && sum(is.na(tsvalues[(train.length + 1):data.length])) > test.length / 2) return(c(judge = 4))
        return(c(judge = 0))
    }
    judge.all <- ddply(data, .(ID1, ID2), businessrule)
    judge.good <- judge.all[judge.all$judge == 0, c("ID1", "ID2")]
    data.good <- join(data, judge.good, by = c("ID1", "ID2"), type = "inner")
    data <- data.good
    # Date format clean-up
    data$time <- as.POSIXct(as.numeric(as.POSIXct(data$time, format = timeformat, tz = "UTC", origin = "1970-01-01"), tz = "UTC"), tz = "UTC", origin = "1970-01-01")
    # Helper functions extracting date-related information
    weeknum <- function(date) { date <- as.Date(date, format = timeformat); as.numeric(format(date, "%U")) }
    year <- function(date) { date <- as.Date(date, format = timeformat); as.numeric(format(date, "%Y")) }
    date.info <- function(df) { date <- df$time[1]; c(year(date), weeknum(date)) }
    # Forecasting Function
    arima.single.id <- function(data) {
        method.name <- "STL_ARIMA"
        # Train and test split
        data.length <- nrow(data)
        train.length <- data.length - horizon
        train <- data[1:train.length,]
        test <- data[(train.length + 1):data.length,]
        # Missing data: replace na with average
        train$obsval[is.na(train$obsval)] <- mean(train$obsval, na.rm = TRUE)
        # Build forecasting models
        train.ts <- ts(train$obsval, frequency = seasonality, start = date.info(train))
        train.model <- stlf(train.ts, h = horizon, method = "arima", s.window = "periodic")
        forecast.value <- train.model$mean
        forecast.lo95 <- train.model$lower[, 1]
        forecast.hi95 <- train.model$upper[, 1]
        output <- data.frame(time = test$time, cbind(forecast.value, forecast.lo95, forecast.hi95))
        colnames(output)[-1] <- paste(c("forecast", "lo95", "hi95"), method.name, sep = ".")
        return(output)
    }
    ##Final forecast values in clean format
    output <- ddply(data, .(ID1, ID2), arima.single.id)
    forecastedvalue <- filter(output, as.Date(time, format = "%m/%d/%Y") == as.Date("12/28/2013", format = "%m/%d/%Y"))
    return(forecastedvalue)
}
predictvalues(2,1)
predictvalues <- function(INID1, INID2) {
    DemoData <- read.csv(file = "C:/Users/Public/Forecast/DemoData.csv", header = TRUE, row.names = NULL, encoding = "UTF-8", sep = ",", dec = ".", quote = "", comment.char = "")
    library(forecast)
    library(dplyr)
    library(plyr)
    library(ggplot2)
    min.length <- 104
    value.threshold <- 20
    test.length <- 8
    horizon <- test.length
    seasonality <- 52
    observation.freq <- "week"
    timeformat <- "%m/%d/%Y"
    INPUTID1 <- INID1
    INPUTID2 <- INID2
    data <- filter(DemoData, ID1 == INPUTID1 & ID2 == INPUTID2)
    # apply business rules
    businessrule <- function(data) {
        tsvalues <- data$obsval
        # Select Eligible Time Series:
        # Rule 1: if a time series has no more than <min.length> non-NA values, discard
        if (sum(!is.na(tsvalues)) < min.length) return(c(judge = 1))
        # Rule 2: if a time series has any sales quantity <= value.threshold , discard
        if (length(tsvalues[tsvalues > value.threshold]) != length(tsvalues)) return(c(judge = 2))
        return(c(judge = 0))
    }
    judge.all <- ddply(data, .(ID1, ID2), businessrule)
    judge.good <- judge.all[judge.all$judge == 0, c("ID1", "ID2")]
    data.good <- join(data, judge.good, by = c("ID1", "ID2"), type = "inner")
    data <- data.good
    data$time <- as.Date(data$obsdttm, format = "%m/%d/%Y")
    min.time <- min(data$time)
    max.time <- max(data$time)
    unique.time <- seq(from = min.time, to = max.time, by = "week")
    # For every (ID1, ID2) pair, create (ID1, ID2, time) combination 
    unique.ID12 <- unique(data[, 1:2])
    comb.ID1 <- rep(unique.ID12$ID1, each = length(unique.time))
    comb.ID2 <- rep(unique.ID12$ID2, each = length(unique.time))
    comb.time <- rep(unique.time, times = dim(unique.ID12)[1])
    comb <- data.frame(ID1 = comb.ID1, ID2 = comb.ID2, time = comb.time)
    # Join the combination with original data
    data <- join(comb, data, by = c("ID1", "ID2", "time"), type = "left")
    # apply business rules
    businessrule <- function(data) {
        # Train and test split
        data.length <- dim(data)[1]
        #test.length <- 52
        train.length <- data.length - test.length
        tsvalues <- data$obsval
        # Select Eligible Time Series based on training and testing principals:
        # Rule 3: if the last 6 values in trainning set are all NA, discard
        if (sum(is.na(tsvalues[(train.length - 5):train.length])) == 6) return(c(judge = 3))
        # Rule 4: if test data has more than a half NA, discard
        if (test.length > 0 && sum(is.na(tsvalues[(train.length + 1):data.length])) > test.length / 2) return(c(judge = 4))
        return(c(judge = 0))
    }
    judge.all <- ddply(data, .(ID1, ID2), businessrule)
    judge.good <- judge.all[judge.all$judge == 0, c("ID1", "ID2")]
    data.good <- join(data, judge.good, by = c("ID1", "ID2"), type = "inner")
    data <- data.good
    # Date format clean-up
    data$time <- as.POSIXct(as.numeric(as.POSIXct(data$time, format = timeformat, tz = "UTC", origin = "1970-01-01"), tz = "UTC"), tz = "UTC", origin = "1970-01-01")
    # Helper functions extracting date-related information
    weeknum <- function(date) { date <- as.Date(date, format = timeformat); as.numeric(format(date, "%U")) }
    year <- function(date) { date <- as.Date(date, format = timeformat); as.numeric(format(date, "%Y")) }
    date.info <- function(df) { date <- df$time[1]; c(year(date), weeknum(date)) }
    # Forecasting Function
    arima.single.id <- function(data) {
        method.name <- "STL_ARIMA"
        # Train and test split
        data.length <- nrow(data)
        train.length <- data.length - horizon
        train <- data[1:train.length,]
        test <- data[(train.length + 1):data.length,]
        # Missing data: replace na with average
        train$obsval[is.na(train$obsval)] <- mean(train$obsval, na.rm = TRUE)
        # Build forecasting models
        train.ts <- ts(train$obsval, frequency = seasonality, start = date.info(train))
        train.model <- stlf(train.ts, h = horizon, method = "arima", s.window = "periodic")
        forecast.value <- train.model$mean
        forecast.lo95 <- train.model$lower[, 1]
        forecast.hi95 <- train.model$upper[, 1]
        output <- data.frame(time = test$time, cbind(forecast.value, forecast.lo95, forecast.hi95))
        colnames(output)[-1] <- paste(c("forecast", "lo95", "hi95"), method.name, sep = ".")
        return(output)
    }
    ##Final forecast values in clean format
    output <- filter(ddply(data, .(ID1, ID2), arima.single.id), as.Date(time, format = "%m/%d/%Y") == as.Date("12/28/2013", format = "%m/%d/%Y"))
    #forecastedvalue <- filter(output, as.Date(time, format = "%m/%d/%Y") == as.Date("12/28/2013", format = "%m/%d/%Y"))
    return(output)
}
predictvalues(2,1)
predictvalues <- function(INID1, INID2) {
    DemoData <- read.csv(file = "C:/Users/Public/Forecast/DemoData.csv", header = TRUE, row.names = NULL, encoding = "UTF-8", sep = ",", dec = ".", quote = "", comment.char = "")
    library(forecast)
    library(dplyr)
    library(plyr)
    library(ggplot2)
    min.length <- 104
    value.threshold <- 20
    test.length <- 8
    horizon <- test.length
    seasonality <- 52
    observation.freq <- "week"
    timeformat <- "%m/%d/%Y"
    INPUTID1 <- INID1
    INPUTID2 <- INID2
    data <- filter(DemoData, ID1 == INPUTID1 & ID2 == INPUTID2)
    # apply business rules
    businessrule <- function(data) {
        tsvalues <- data$obsval
        # Select Eligible Time Series:
        # Rule 1: if a time series has no more than <min.length> non-NA values, discard
        if (sum(!is.na(tsvalues)) < min.length) return(c(judge = 1))
        # Rule 2: if a time series has any sales quantity <= value.threshold , discard
        if (length(tsvalues[tsvalues > value.threshold]) != length(tsvalues)) return(c(judge = 2))
        return(c(judge = 0))
    }
    judge.all <- ddply(data, .(ID1, ID2), businessrule)
    judge.good <- judge.all[judge.all$judge == 0, c("ID1", "ID2")]
    data.good <- join(data, judge.good, by = c("ID1", "ID2"), type = "inner")
    data <- data.good
    data$time <- as.Date(data$obsdttm, format = "%m/%d/%Y")
    min.time <- min(data$time)
    max.time <- max(data$time)
    unique.time <- seq(from = min.time, to = max.time, by = "week")
    # For every (ID1, ID2) pair, create (ID1, ID2, time) combination 
    unique.ID12 <- unique(data[, 1:2])
    comb.ID1 <- rep(unique.ID12$ID1, each = length(unique.time))
    comb.ID2 <- rep(unique.ID12$ID2, each = length(unique.time))
    comb.time <- rep(unique.time, times = dim(unique.ID12)[1])
    comb <- data.frame(ID1 = comb.ID1, ID2 = comb.ID2, time = comb.time)
    # Join the combination with original data
    data <- join(comb, data, by = c("ID1", "ID2", "time"), type = "left")
    # apply business rules
    businessrule <- function(data) {
        # Train and test split
        data.length <- dim(data)[1]
        #test.length <- 52
        train.length <- data.length - test.length
        tsvalues <- data$obsval
        # Select Eligible Time Series based on training and testing principals:
        # Rule 3: if the last 6 values in trainning set are all NA, discard
        if (sum(is.na(tsvalues[(train.length - 5):train.length])) == 6) return(c(judge = 3))
        # Rule 4: if test data has more than a half NA, discard
        if (test.length > 0 && sum(is.na(tsvalues[(train.length + 1):data.length])) > test.length / 2) return(c(judge = 4))
        return(c(judge = 0))
    }
    judge.all <- ddply(data, .(ID1, ID2), businessrule)
    judge.good <- judge.all[judge.all$judge == 0, c("ID1", "ID2")]
    data.good <- join(data, judge.good, by = c("ID1", "ID2"), type = "inner")
    data <- data.good
    # Date format clean-up
    data$time <- as.POSIXct(as.numeric(as.POSIXct(data$time, format = timeformat, tz = "UTC", origin = "1970-01-01"), tz = "UTC"), tz = "UTC", origin = "1970-01-01")
    # Helper functions extracting date-related information
    weeknum <- function(date) { date <- as.Date(date, format = timeformat); as.numeric(format(date, "%U")) }
    year <- function(date) { date <- as.Date(date, format = timeformat); as.numeric(format(date, "%Y")) }
    date.info <- function(df) { date <- df$time[1]; c(year(date), weeknum(date)) }
    # Forecasting Function
    arima.single.id <- function(data) {
        method.name <- "STL_ARIMA"
        # Train and test split
        data.length <- nrow(data)
        train.length <- data.length - horizon
        train <- data[1:train.length,]
        test <- data[(train.length + 1):data.length,]
        # Missing data: replace na with average
        train$obsval[is.na(train$obsval)] <- mean(train$obsval, na.rm = TRUE)
        # Build forecasting models
        train.ts <- ts(train$obsval, frequency = seasonality, start = date.info(train))
        train.model <- stlf(train.ts, h = horizon, method = "arima", s.window = "periodic")
        forecast.value <- train.model$mean
        forecast.lo95 <- train.model$lower[, 1]
        forecast.hi95 <- train.model$upper[, 1]
        output <- data.frame(time = test$time, cbind(forecast.value, forecast.lo95, forecast.hi95))
        colnames(output)[-1] <- paste(c("forecast", "lo95", "hi95"), method.name, sep = ".")
        return(output)
    }
    ##Final forecast values in clean format
    output <- filter(ddply(data, .(ID1, ID2), arima.single.id), as.Date(time, format = "%m/%d/%Y") == as.Date("12/28/2013", format = "%m/%d/%Y"))
    #forecastedvalue <- filter(output, as.Date(time, format = "%m/%d/%Y") == as.Date("12/28/2013", format = "%m/%d/%Y"))
    return(output$forecast.STL_ARIMA)
}
predictvalues(2,1)
is.numeric(predictvalues(2, 1))
predictvalues <- function(INID1, INID2, INDATE) {
    DemoData <- read.csv(file = "C:/Users/Public/Forecast/DemoData.csv", header = TRUE, row.names = NULL, encoding = "UTF-8", sep = ",", dec = ".", quote = "", comment.char = "")
    library(forecast)
    library(dplyr)
    library(plyr)
    library(ggplot2)
    min.length <- 104
    value.threshold <- 20
    test.length <- 8
    horizon <- test.length
    seasonality <- 52
    observation.freq <- "week"
    timeformat <- "%m/%d/%Y"
    INPUTID1 <- INID1
    INPUTID2 <- INID2
    INPUTDATE <- INDATE
    data <- filter(DemoData, ID1 == INPUTID1 & ID2 == INPUTID2)
    # apply business rules
    businessrule <- function(data) {
        tsvalues <- data$obsval
        # Select Eligible Time Series:
        # Rule 1: if a time series has no more than <min.length> non-NA values, discard
        if (sum(!is.na(tsvalues)) < min.length) return(c(judge = 1))
        # Rule 2: if a time series has any sales quantity <= value.threshold , discard
        if (length(tsvalues[tsvalues > value.threshold]) != length(tsvalues)) return(c(judge = 2))
        return(c(judge = 0))
    }
    judge.all <- ddply(data, .(ID1, ID2), businessrule)
    judge.good <- judge.all[judge.all$judge == 0, c("ID1", "ID2")]
    data.good <- join(data, judge.good, by = c("ID1", "ID2"), type = "inner")
    data <- data.good
    data$time <- as.Date(data$obsdttm, format = "%m/%d/%Y")
    min.time <- min(data$time)
    max.time <- max(data$time)
    unique.time <- seq(from = min.time, to = max.time, by = "week")
    # For every (ID1, ID2) pair, create (ID1, ID2, time) combination 
    unique.ID12 <- unique(data[, 1:2])
    comb.ID1 <- rep(unique.ID12$ID1, each = length(unique.time))
    comb.ID2 <- rep(unique.ID12$ID2, each = length(unique.time))
    comb.time <- rep(unique.time, times = dim(unique.ID12)[1])
    comb <- data.frame(ID1 = comb.ID1, ID2 = comb.ID2, time = comb.time)
    # Join the combination with original data
    data <- join(comb, data, by = c("ID1", "ID2", "time"), type = "left")
    # apply business rules
    businessrule <- function(data) {
        # Train and test split
        data.length <- dim(data)[1]
        #test.length <- 52
        train.length <- data.length - test.length
        tsvalues <- data$obsval
        # Select Eligible Time Series based on training and testing principals:
        # Rule 3: if the last 6 values in trainning set are all NA, discard
        if (sum(is.na(tsvalues[(train.length - 5):train.length])) == 6) return(c(judge = 3))
        # Rule 4: if test data has more than a half NA, discard
        if (test.length > 0 && sum(is.na(tsvalues[(train.length + 1):data.length])) > test.length / 2) return(c(judge = 4))
        return(c(judge = 0))
    }
    judge.all <- ddply(data, .(ID1, ID2), businessrule)
    judge.good <- judge.all[judge.all$judge == 0, c("ID1", "ID2")]
    data.good <- join(data, judge.good, by = c("ID1", "ID2"), type = "inner")
    data <- data.good
    # Date format clean-up
    data$time <- as.POSIXct(as.numeric(as.POSIXct(data$time, format = timeformat, tz = "UTC", origin = "1970-01-01"), tz = "UTC"), tz = "UTC", origin = "1970-01-01")
    # Helper functions extracting date-related information
    weeknum <- function(date) { date <- as.Date(date, format = timeformat); as.numeric(format(date, "%U")) }
    year <- function(date) { date <- as.Date(date, format = timeformat); as.numeric(format(date, "%Y")) }
    date.info <- function(df) { date <- df$time[1]; c(year(date), weeknum(date)) }
    # Forecasting Function
    arima.single.id <- function(data) {
        method.name <- "STL_ARIMA"
        # Train and test split
        data.length <- nrow(data)
        train.length <- data.length - horizon
        train <- data[1:train.length,]
        test <- data[(train.length + 1):data.length,]
        # Missing data: replace na with average
        train$obsval[is.na(train$obsval)] <- mean(train$obsval, na.rm = TRUE)
        # Build forecasting models
        train.ts <- ts(train$obsval, frequency = seasonality, start = date.info(train))
        train.model <- stlf(train.ts, h = horizon, method = "arima", s.window = "periodic")
        forecast.value <- train.model$mean
        forecast.lo95 <- train.model$lower[, 1]
        forecast.hi95 <- train.model$upper[, 1]
        output <- data.frame(time = test$time, cbind(forecast.value, forecast.lo95, forecast.hi95))
        colnames(output)[-1] <- paste(c("forecast", "lo95", "hi95"), method.name, sep = ".")
        return(output)
    }
    ##Final forecast values in clean format
    output <- filter(ddply(data, .(ID1, ID2), arima.single.id), as.Date(time, format = "%m/%d/%Y") == as.Date(INPUTDATE, format = "%m/%d/%Y"))
    #forecastedvalue <- filter(output, as.Date(time, format = "%m/%d/%Y") == as.Date("12/28/2013", format = "%m/%d/%Y"))
    return(output)
}
predictvalues("12/28/2013",1,2)
predictvalues(1,2,"12/28/2013")
predictvalues <- function(INID1, INID2, INDATE) {
    DemoData <- read.csv(file = "C:/Users/Public/Forecast/DemoData.csv", header = TRUE, row.names = NULL, encoding = "UTF-8", sep = ",", dec = ".", quote = "", comment.char = "")
    library(forecast)
    library(dplyr)
    library(plyr)
    library(ggplot2)
    min.length <- 104
    value.threshold <- 20
    test.length <- 8
    horizon <- test.length
    seasonality <- 52
    observation.freq <- "week"
    timeformat <- "%m/%d/%Y"
    INPUTID1 <- INID1
    INPUTID2 <- INID2
    INPUTDATE <- INDATE
    data <- filter(DemoData, ID1 == INPUTID1 & ID2 == INPUTID2)
    # apply business rules
    businessrule <- function(data) {
        tsvalues <- data$obsval
        # Select Eligible Time Series:
        # Rule 1: if a time series has no more than <min.length> non-NA values, discard
        if (sum(!is.na(tsvalues)) < min.length) return(c(judge = 1))
        # Rule 2: if a time series has any sales quantity <= value.threshold , discard
        if (length(tsvalues[tsvalues > value.threshold]) != length(tsvalues)) return(c(judge = 2))
        return(c(judge = 0))
    }
    judge.all <- ddply(data, .(ID1, ID2), businessrule)
    judge.good <- judge.all[judge.all$judge == 0, c("ID1", "ID2")]
    data.good <- join(data, judge.good, by = c("ID1", "ID2"), type = "inner")
    data <- data.good
    data$time <- as.Date(data$obsdttm, format = "%m/%d/%Y")
    min.time <- min(data$time)
    max.time <- max(data$time)
    unique.time <- seq(from = min.time, to = max.time, by = "week")
    # For every (ID1, ID2) pair, create (ID1, ID2, time) combination 
    unique.ID12 <- unique(data[, 1:2])
    comb.ID1 <- rep(unique.ID12$ID1, each = length(unique.time))
    comb.ID2 <- rep(unique.ID12$ID2, each = length(unique.time))
    comb.time <- rep(unique.time, times = dim(unique.ID12)[1])
    comb <- data.frame(ID1 = comb.ID1, ID2 = comb.ID2, time = comb.time)
    # Join the combination with original data
    data <- join(comb, data, by = c("ID1", "ID2", "time"), type = "left")
    # apply business rules
    businessrule <- function(data) {
        # Train and test split
        data.length <- dim(data)[1]
        #test.length <- 52
        train.length <- data.length - test.length
        tsvalues <- data$obsval
        # Select Eligible Time Series based on training and testing principals:
        # Rule 3: if the last 6 values in trainning set are all NA, discard
        if (sum(is.na(tsvalues[(train.length - 5):train.length])) == 6) return(c(judge = 3))
        # Rule 4: if test data has more than a half NA, discard
        if (test.length > 0 && sum(is.na(tsvalues[(train.length + 1):data.length])) > test.length / 2) return(c(judge = 4))
        return(c(judge = 0))
    }
    judge.all <- ddply(data, .(ID1, ID2), businessrule)
    judge.good <- judge.all[judge.all$judge == 0, c("ID1", "ID2")]
    data.good <- join(data, judge.good, by = c("ID1", "ID2"), type = "inner")
    data <- data.good
    # Date format clean-up
    data$time <- as.POSIXct(as.numeric(as.POSIXct(data$time, format = timeformat, tz = "UTC", origin = "1970-01-01"), tz = "UTC"), tz = "UTC", origin = "1970-01-01")
    # Helper functions extracting date-related information
    weeknum <- function(date) { date <- as.Date(date, format = timeformat); as.numeric(format(date, "%U")) }
    year <- function(date) { date <- as.Date(date, format = timeformat); as.numeric(format(date, "%Y")) }
    date.info <- function(df) { date <- df$time[1]; c(year(date), weeknum(date)) }
    # Forecasting Function
    arima.single.id <- function(data) {
        method.name <- "STL_ARIMA"
        # Train and test split
        data.length <- nrow(data)
        train.length <- data.length - horizon
        train <- data[1:train.length,]
        test <- data[(train.length + 1):data.length,]
        # Missing data: replace na with average
        train$obsval[is.na(train$obsval)] <- mean(train$obsval, na.rm = TRUE)
        # Build forecasting models
        train.ts <- ts(train$obsval, frequency = seasonality, start = date.info(train))
        train.model <- stlf(train.ts, h = horizon, method = "arima", s.window = "periodic")
        forecast.value <- train.model$mean
        forecast.lo95 <- train.model$lower[, 1]
        forecast.hi95 <- train.model$upper[, 1]
        output <- data.frame(time = test$time, cbind(forecast.value, forecast.lo95, forecast.hi95))
        colnames(output)[-1] <- paste(c("forecast", "lo95", "hi95"), method.name, sep = ".")
        return(output)
    }
    ##Final forecast values in clean format
    output <- filter(ddply(data, .(ID1, ID2), arima.single.id), as.Date(time, format = "%m/%d/%Y") == as.Date(INPUTDATE, format = "%m/%d/%Y"))
    #forecastedvalue <- filter(output, as.Date(time, format = "%m/%d/%Y") == as.Date("12/28/2013", format = "%m/%d/%Y"))
    return(output$forecast.STL_ARIMA)
}
predictvalues(1,2,"12/28/2013")
api <- publishService(   name =   "forecastservice", code = predictvalues,      inputs = list(INID1 = "numeric", INID2 = "numeric", INDATE = "numeric"),      outputs = list(answer = "numeric"),      v = "v2.0.0" )
remoteLogin("http://srramr2.southcentralus.cloudapp.azure.com:12800", prompt = "R>")
pause
pause()
api <- publishService(   name =   "forecastservice", code = predictvalues,      inputs = list(INID1 = "numeric", INID2 = "numeric", INDATE = "numeric"),      outputs = list(answer = "numeric"),      v = "v2.0.0" )
api <- getService("forecastservice", v = "v2.0.0")
result <- api$consume(1,2,"12/28/2013")
api <- publishService(   name =   "forecastservice", code = predictvalues,      inputs = list(INID1 = "numeric", INID2 = "numeric", INDATE = "character"),      outputs = list(answer = "numeric"),      v = "v2.0.1" )
api <- getService("forecastservice", v = "v2.0.1")
result <- api$consume(1,2,"12/28/2013")
result$output("answer")\
result$output("answer")
result$output("answer")*1000
result <- api$consume(2,1,"12/28/2013")
result$output("answer")*1000
swagger <- api$swagger() cat(swagger, file = "swaggerfinal.json", append = FALSE)
remote
remoteLogout
remoteLogout()
DemoData <- read.csv(file = "C:/Users/srram/Desktop/DemoData.csv", header = TRUE, row.names = NULL, encoding = "UTF-8", sep = ",", dec = ".", quote = "", comment.char = "") library(forecast) library(dplyr) library(plyr) library(ggplot2) min.length <- 104 value.threshold <- 20 test.length <- 8 horizon <- test.length seasonality <- 52 observation.freq <- "week" timeformat <- "%m/%d/%Y" INPUTID1 <- 1 INPUTID2 <- 2 data <- filter(DemoData, ID1 == INPUTID1 & ID2 == INPUTID2) # apply business rules businessrule <- function(data) {   tsvalues <- data$obsval   # Select Eligible Time Series:   # Rule 1: if a time series has no more than <min.length> non-NA values, discard   if (sum(!is.na(tsvalues)) < min.length) return(c(judge = 1))   # Rule 2: if a time series has any sales quantity <= value.threshold , discard   if (length(tsvalues[tsvalues > value.threshold]) != length(tsvalues)) return(c(judge = 2))   return(c(judge = 0)) } judge.all <- ddply(data, .(ID1, ID2), businessrule) judge.good <- judge.all[judge.all$judge == 0, c("ID1", "ID2")] data.good <- join(data, judge.good, by = c("ID1", "ID2"), type = "inner") data <- data.good data$time <- as.Date(data$obsdttm, format = "%m/%d/%Y") min.time <- min(data$time) max.time <- max(data$time) unique.time <- seq(from = min.time, to = max.time, by = "week") # For every (ID1, ID2) pair, create (ID1, ID2, time) combination  unique.ID12 <- unique(data[, 1:2]) comb.ID1 <- rep(unique.ID12$ID1, each = length(unique.time)) comb.ID2 <- rep(unique.ID12$ID2, each = length(unique.time)) comb.time <- rep(unique.time, times = dim(unique.ID12)[1]) comb <- data.frame(ID1 = comb.ID1, ID2 = comb.ID2, time = comb.time) # Join the combination with original data data <- join(comb, data, by = c("ID1", "ID2", "time"), type = "left") # apply business rules businessrule <- function(data) {   # Train and test split   data.length <- dim(data)[1]   #test.length <- 52   train.length <- data.length - test.length   tsvalues <- data$obsval   # Select Eligible Time Series based on training and testing principals:   # Rule 3: if the last 6 values in trainning set are all NA, discard   if (sum(is.na(tsvalues[(train.length - 5):train.length])) == 6) return(c(judge = 3))   # Rule 4: if test data has more than a half NA, discard   if (test.length > 0 && sum(is.na(tsvalues[(train.length + 1):data.length])) > test.length / 2) return(c(judge = 4))   return(c(judge = 0)) } judge.all <- ddply(data, .(ID1, ID2), businessrule) judge.good <- judge.all[judge.all$judge == 0, c("ID1", "ID2")] data.good <- join(data, judge.good, by = c("ID1", "ID2"), type = "inner") data <- data.good data$time <- as.POSIXct(as.numeric(as.POSIXct(data$time, format = timeformat, tz = "UTC", origin = "1970-01-01"), tz = "UTC"), tz = "UTC", origin = "1970-01-01") weeknum <- function(date) { date <- as.Date(date, format = timeformat); as.numeric(format(date, "%U")) } year <- function(date) { date <- as.Date(date, format = timeformat); as.numeric(format(date, "%Y")) } date.info <- function(df) { date <- df$time[1]; c(year(date), weeknum(date)) } # Train and test split data.length <- nrow(data) # Missing data: replace na with average data$obsval[is.na(data$obsval)] <- mean(data$obsval, na.rm = TRUE)
ggplot(data, aes(x = time)) + geom_line(aes(y = obsval), color = "black") + facet_grid(ID1~ID2)
acf(my.ts) pacf(my.ts)
my.ts <- ts(data$obsval, frequency = seasonality, start = date.info(data))
acf(my.ts) pacf(my.ts)
ggplot(data, aes(x = time)) + geom_line(aes(y = obsval), color = "black") + facet_grid(ID1~ID2)
myarimamodel <- auto.arima(my.ts)
myarimamodel
tsdiag(myarimamodel)
plot(forecast(myarimamodel, h = 5))
remoteLogin("http://srramr2.southcentralus.cloudapp.azure.com:12800", prompt = "R>")
pause()
resume()
data <- truevsforecast # class: data.frame ## ------- User-Defined Parameters ------ ## test.length <- 52 seasonality <- 52 observation.freq <- "week" timeformat <- "%m/%d/%Y" ## ----------------------------------------- ## input<- data.frame(test.length = test.length, seasonality = seasonality,                     observation.freq = observation.freq, timeformat = timeformat, stringsAsFactors = FALSE) attach(input) # Date format clean-up data$time <- as.POSIXct(as.numeric(as.POSIXct(data$time, format = timeformat, tz = "UTC", origin = "1970-01-01"), tz = "UTC"), tz = "UTC", origin = "1970-01-01") # Helper function extract.col <- function(pattern, df = data){   col.indices <- grep(pattern, colnames(df), ignore.case = TRUE)   return(df[, col.indices, drop = FALSE]) } # Metric Functions library(forecast) mase <- function(true, forecast){   error = 0;   if (length(true) != length(forecast)) {     return (NA);   } else if (length(true) == 0 || length(forecast) == 0) {     return (NA);   }   else {     denom = (sum(abs(true[2:length(true)] - true[1:(length(true) - 1)])))/(length(true) - 1)     error = sum((abs(true-forecast)) / denom)/length(true);   }   return (error); } metrics <- function(true, forecast){   forecast.metrics <- as.data.frame(accuracy(forecast, true))   return(data.frame(forecast.metrics[, colnames(forecast.metrics) !="ME"], MASE = mase(true, forecast))) } # Extract forecast values data.forecast <- extract.col("forecast\\.[a_z]*") # Split true data and forecast values is.test <- !is.na(data.forecast[,1]) test.true <- data$value[is.test] test.forecast <- data.forecast[is.test, ] test.time <- data$time[is.test] test.nonna <- complete.cases(test.true) test.true <- test.true[test.nonna] test.forecast <- test.forecast[test.nonna,] test.time <- test.time[test.nonna] # Calculate error metrics output <- t(sapply(test.forecast, metrics, true = test.true)) methods <- sub("[a-z]+\\.", "", rownames(output), ignore.case = TRUE) output <- apply(output, c(1,2),as.numeric) output <- data.frame(Method = methods, output) rownames(output) <- NULL # Plot time <- data$time true <- as.numeric(data$value) value.data <- unlist(data[, !(names(data) %in% c("time", "ID1", "ID2"))]) min.data <- min(value.data, na.rm = TRUE) max.data <- max(value.data, na.rm = TRUE) graph.ts <- function(method){   forecast.value <- data[, paste("forecast.", method, sep = "")]   have.ci <- tryCatch(     {       lo95 <- data[, paste("lo95.", method, sep = "")]       hi95 <- data[, paste("hi95.", method, sep = "")]       have.ci <- TRUE     },     error = function(e){       have.ci <- FALSE     }   )   graph.title <- paste("Forecast by", method)   plot(time, true, type="l",col="blue",xlab="Time",ylab="Data",lwd=2, bty="l", main = "Time Series Plot", ylim = c(min(0,min.data*0.95), max.data * 1.05))   grid(col = "gray")   lines(time, forecast.value, col = "red", lwd = 2)   # plot confidence interval   if (have.ci){     ci.color <- adjustcolor("gray",alpha.f=0.5)     lines(time, lo95, col = ci.color, lwd = 2)     lines(time, hi95, col = ci.color, lwd = 2)     polygon(c(time, rev(time)), c(hi95, rev(lo95)), col = ci.color, border = NA)     # add legend     legend("top",legend = c("True Data", "Forecast", "95% Confidence Interval"),            bty=c("n","n"), lty=c(1, 1, 1), lwd = c(2, 2, 10), horiz = TRUE,            col=c("blue","red", ci.color), cex = 1.5)   }   else{     # add legend     legend("top",legend = c("True Data", "Forecast"),            bty=c("n","n"), lty=c(1, 1), lwd = c(2, 2), horiz = TRUE,            col=c("blue","red"), cex = 1.5)     return(NULL)   } } error.forecast <- apply(test.forecast, 2, "-", test.true) colnames(error.forecast) <- sub("forecast", "error", colnames(error.forecast)) max.abs.error <- max(abs(error.forecast), na.rm = TRUE) graph.error <- function(method){   error <- error.forecast[, paste("error.", method, sep = "")]   error.mean <- mean(error)   error.sd <- sd(error)   # error vs time   plot(test.time, error, type = "h", bty = "l", xlab = "Time", ylab = "Prediction Error",         main = "Prediction Error VS Time",  ylim = c(-max.abs.error, max.abs.error))   abline(0,0)   abline(1.96*error.sd, 0, lty = 2, col = "blue")   abline(-1.96*error.sd, 0, lty = 2, col = "blue")   # error histogram   error.hist <- hist(error, density = 20, bty = "l", xlab = "Prediction Error",                       main = "Histogram of Prediction Error", xlim = c(-max.abs.error*1.1, max.abs.error*1.1))   x <- (-max.abs.error*1.1) : (max.abs.error*1.1)   multiplier <- (error.hist$counts / error.hist$density)[1]   lines(x, dnorm(x, 0, error.sd)*multiplier, col = "red")   # ACF and PACF   acf(error, main = "", bty = "l", ylim = c(-1, 1))   title("Auto-Correlation Function of Errors", line = 1)   pacf(error, , main = "", bty = "l", ylim = c(-1, 1), xlim = c(1, 20))   title("Partial Auto-Correlation Function of Errors", line = 1)   return(NULL) } ID1 <- data$ID1[1] ID2 <- data$ID2[1] graph <- function(method){   png(filename = paste(method,".png", sep = ""), width = 1080, height = 1620)   layout(matrix(c(1,1,2,3,4,5), 3, 2, byrow = TRUE), heights = c(1.1, 1, 1))   par(oma = c(1, 1.2, 3, 1), mar = c(3.5, 3.5, 2, 1), mgp = c(1.8, 0.5, 0),        cex.lab=1.4, cex.axis=1.3, cex.main=2, cex.sub=1.5)   graph.ts(method)  # graph.error(method)   graph.title <- paste("Model Goodness of", method, "for ID1 =", ID1, "and ID2 =", ID2)   title(graph.title, outer = TRUE)   box("inner", lty = 3)   dev.off() } g <- lapply(methods, FUN = graph)
`truevsforecast` <- read.csv(file="C:/Users/srram/AppData/Local/Temp/truevsforecast.csv.utf8", header=TRUE, row.names=NULL, encoding="UTF-8", sep=",", dec=".", quote="\"", comment.char="")
